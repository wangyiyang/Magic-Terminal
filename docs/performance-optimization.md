# Magic Terminal æ€§èƒ½ä¼˜åŒ–æŒ‡å—

## ğŸ¯ æ€§èƒ½ç›®æ ‡

Magic Terminal çš„æ€§èƒ½ä¼˜åŒ–ç›®æ ‡ï¼š

- **å¯åŠ¨æ—¶é—´**: < 500ms (å†·å¯åŠ¨)
- **å†…å­˜å ç”¨**: < 50MB (ç©ºé—²çŠ¶æ€)
- **CPU ä½¿ç”¨**: < 1% (ç©ºé—²æ—¶)
- **æ¸²æŸ“å¸§ç‡**: 60+ FPS
- **è¾“å…¥å»¶è¿Ÿ**: < 10ms
- **å¤§æ–‡ä»¶å¤„ç†**: æ”¯æŒ MB çº§åˆ«è¾“å‡º

## ğŸ“Š æ€§èƒ½åˆ†æå·¥å…·

### Go å†…ç½®å·¥å…·

#### pprof æ€§èƒ½åˆ†æ

```go
// å¯ç”¨æ€§èƒ½åˆ†æ
import (
    _ "net/http/pprof"
    "net/http"
    "log"
)

func enableProfiling() {
    go func() {
        log.Println("å¯åŠ¨æ€§èƒ½åˆ†ææœåŠ¡: http://localhost:6060/debug/pprof/")
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
}

// åœ¨ main å‡½æ•°ä¸­è°ƒç”¨
func main() {
    if os.Getenv("ENABLE_PPROF") == "true" {
        enableProfiling()
    }
    // ... åº”ç”¨ç¨‹åºé€»è¾‘
}
```

#### ä½¿ç”¨ pprof åˆ†æ

```bash
# CPU åˆ†æ
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30

# å†…å­˜åˆ†æ
go tool pprof http://localhost:6060/debug/pprof/heap

# Goroutine åˆ†æ
go tool pprof http://localhost:6060/debug/pprof/goroutine

# åœ¨ pprof äº¤äº’ç•Œé¢ä¸­
(pprof) top10      # æ˜¾ç¤ºå ç”¨æœ€é«˜çš„10ä¸ªå‡½æ•°
(pprof) list main  # æ˜¾ç¤º main å‡½æ•°çš„è¯¦ç»†ä¿¡æ¯
(pprof) web        # ç”Ÿæˆè°ƒç”¨å›¾
```

#### trace è¿½è¸ªåˆ†æ

```go
// ç”Ÿæˆ trace æ–‡ä»¶
import (
    "os"
    "runtime/trace"
)

func enableTracing() {
    f, err := os.Create("trace.out")
    if err != nil {
        panic(err)
    }
    defer f.Close()
    
    if err := trace.Start(f); err != nil {
        panic(err)
    }
    defer trace.Stop()
    
    // åº”ç”¨ç¨‹åºè¿è¡Œ
}
```

```bash
# åˆ†æ trace æ–‡ä»¶
go tool trace trace.out
```

### ç¬¬ä¸‰æ–¹å·¥å…·

#### æ€§èƒ½ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# scripts/monitor-performance.sh

PID=$(pgrep magic-terminal)
if [[ -z "$PID" ]]; then
    echo "Magic Terminal æœªè¿è¡Œ"
    exit 1
fi

echo "ç›‘æ§ Magic Terminal æ€§èƒ½ (PID: $PID)"
echo "æ—¶é—´,CPU(%),å†…å­˜(MB),æ–‡ä»¶æè¿°ç¬¦"

while true; do
    # CPU ä½¿ç”¨ç‡
    CPU=$(ps -p $PID -o pcpu= | tr -d ' ')
    
    # å†…å­˜ä½¿ç”¨ (MB)
    MEM=$(ps -p $PID -o rss= | awk '{print $1/1024}')
    
    # æ–‡ä»¶æè¿°ç¬¦æ•°é‡
    FD_COUNT=$(lsof -p $PID 2>/dev/null | wc -l)
    
    # æ—¶é—´æˆ³
    TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')
    
    echo "$TIMESTAMP,$CPU,$MEM,$FD_COUNT"
    
    sleep 5
done
```

## ğŸš€ å¯åŠ¨æ€§èƒ½ä¼˜åŒ–

### å»¶è¿Ÿåˆå§‹åŒ–

```go
// ä½¿ç”¨ sync.Once è¿›è¡Œå»¶è¿Ÿåˆå§‹åŒ–
type Terminal struct {
    // ... å…¶ä»–å­—æ®µ
    
    rendererOnce sync.Once
    renderer     *RenderEngine
    
    themeOnce sync.Once
    theme     *ThemeManager
}

func (t *Terminal) getRenderer() *RenderEngine {
    t.rendererOnce.Do(func() {
        t.renderer = NewRenderEngine(t)
    })
    return t.renderer
}

func (t *Terminal) getTheme() *ThemeManager {
    t.themeOnce.Do(func() {
        t.theme = NewThemeManager()
    })
    return t.theme
}
```

### é¢„ç¼–è¯‘æ¨¡æ¿å’Œèµ„æº

```go
//go:embed translation/*.json
var translationFS embed.FS

// é¢„è§£æç¿»è¯‘æ–‡ä»¶
var translations map[string]map[string]string

func init() {
    translations = make(map[string]map[string]string)
    
    entries, _ := translationFS.ReadDir("translation")
    for _, entry := range entries {
        if strings.HasSuffix(entry.Name(), ".json") {
            lang := strings.TrimSuffix(entry.Name(), ".json")
            data, _ := translationFS.ReadFile("translation/" + entry.Name())
            
            var langMap map[string]string
            json.Unmarshal(data, &langMap)
            translations[lang] = langMap
        }
    }
}
```

### é…ç½®ç¼“å­˜

```go
type ConfigCache struct {
    cache    map[string]interface{}
    mu       sync.RWMutex
    lastLoad time.Time
    ttl      time.Duration
}

func (c *ConfigCache) Get(key string) (interface{}, bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()
    
    // æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
    if time.Since(c.lastLoad) > c.ttl {
        return nil, false
    }
    
    value, exists := c.cache[key]
    return value, exists
}

func (c *ConfigCache) Set(key string, value interface{}) {
    c.mu.Lock()
    defer c.mu.Unlock()
    
    if c.cache == nil {
        c.cache = make(map[string]interface{})
    }
    
    c.cache[key] = value
    c.lastLoad = time.Now()
}
```

## ğŸ–¼ï¸ æ¸²æŸ“æ€§èƒ½ä¼˜åŒ–

### è„åŒºåŸŸæ¸²æŸ“

```go
type DirtyRegion struct {
    X, Y          int
    Width, Height int
    Priority      int
}

type RenderEngine struct {
    dirtyRegions []DirtyRegion
    fullRedraw   bool
    mu           sync.Mutex
}

func (r *RenderEngine) MarkDirty(x, y, width, height int) {
    r.mu.Lock()
    defer r.mu.Unlock()
    
    region := DirtyRegion{
        X: x, Y: y,
        Width: width, Height: height,
        Priority: calculatePriority(x, y, width, height),
    }
    
    r.dirtyRegions = append(r.dirtyRegions, region)
    
    // åˆå¹¶é‡å åŒºåŸŸ
    r.mergeOverlappingRegions()
}

func (r *RenderEngine) mergeOverlappingRegions() {
    // ä½¿ç”¨åŒºé—´åˆå¹¶ç®—æ³•å‡å°‘é‡ç»˜åŒºåŸŸ
    merged := make([]DirtyRegion, 0, len(r.dirtyRegions))
    
    for _, region := range r.dirtyRegions {
        wasmerged := false
        
        for i := range merged {
            if r.regionsOverlap(merged[i], region) {
                merged[i] = r.mergeRegions(merged[i], region)
                wasmerged = true
                break
            }
        }
        
        if !wasmerged {
            merged = append(merged, region)
        }
    }
    
    r.dirtyRegions = merged
}
```

### åŒç¼“å†²æ¸²æŸ“

```go
type DoubleBuffer struct {
    frontBuffer [][]Cell
    backBuffer  [][]Cell
    rows        int
    cols        int
    mu          sync.RWMutex
}

func (db *DoubleBuffer) SwapBuffers() {
    db.mu.Lock()
    defer db.mu.Unlock()
    
    db.frontBuffer, db.backBuffer = db.backBuffer, db.frontBuffer
}

func (db *DoubleBuffer) WriteToBack(row, col int, cell Cell) {
    db.mu.Lock()
    defer db.mu.Unlock()
    
    if row >= 0 && row < db.rows && col >= 0 && col < db.cols {
        db.backBuffer[row][col] = cell
    }
}

func (db *DoubleBuffer) ReadFromFront(row, col int) Cell {
    db.mu.RLock()
    defer db.mu.RUnlock()
    
    if row >= 0 && row < db.rows && col >= 0 && col < db.cols {
        return db.frontBuffer[row][col]
    }
    return Cell{}
}
```

### å­—ä½“ç¼“å­˜

```go
type FontCache struct {
    cache       map[FontKey]*font.Face
    metrics     map[FontKey]FontMetrics
    maxSize     int
    accessOrder []FontKey
    mu          sync.RWMutex
}

type FontKey struct {
    Family string
    Size   float32
    Style  FontStyle
}

func (fc *FontCache) GetFont(key FontKey) *font.Face {
    fc.mu.RLock()
    face, exists := fc.cache[key]
    fc.mu.RUnlock()
    
    if exists {
        fc.updateAccessOrder(key)
        return face
    }
    
    return fc.loadFont(key)
}

func (fc *FontCache) loadFont(key FontKey) *font.Face {
    fc.mu.Lock()
    defer fc.mu.Unlock()
    
    // æ£€æŸ¥ç¼“å­˜å¤§å°
    if len(fc.cache) >= fc.maxSize {
        fc.evictLRU()
    }
    
    // åŠ è½½å­—ä½“
    face := loadFontFace(key)
    fc.cache[key] = face
    fc.accessOrder = append(fc.accessOrder, key)
    
    return face
}
```

## ğŸ’¾ å†…å­˜ä¼˜åŒ–

### å¯¹è±¡æ± 

```go
// Cell å¯¹è±¡æ± 
var cellPool = sync.Pool{
    New: func() interface{} {
        return &Cell{}
    },
}

func GetCell() *Cell {
    return cellPool.Get().(*Cell)
}

func PutCell(cell *Cell) {
    cell.Reset() // é‡ç½®çŠ¶æ€
    cellPool.Put(cell)
}

// ç¼“å†²åŒºå¯¹è±¡æ± 
type BufferPool struct {
    pools map[int]*sync.Pool
    mu    sync.RWMutex
}

func NewBufferPool() *BufferPool {
    return &BufferPool{
        pools: make(map[int]*sync.Pool),
    }
}

func (bp *BufferPool) Get(size int) []byte {
    bp.mu.RLock()
    pool, exists := bp.pools[size]
    bp.mu.RUnlock()
    
    if !exists {
        bp.mu.Lock()
        pool = &sync.Pool{
            New: func() interface{} {
                return make([]byte, size)
            },
        }
        bp.pools[size] = pool
        bp.mu.Unlock()
    }
    
    return pool.Get().([]byte)
}

func (bp *BufferPool) Put(buf []byte) {
    size := cap(buf)
    
    bp.mu.RLock()
    pool, exists := bp.pools[size]
    bp.mu.RUnlock()
    
    if exists {
        pool.Put(buf[:0]) // é‡ç½®é•¿åº¦ä½†ä¿ç•™å®¹é‡
    }
}
```

### å†…å­˜ä½¿ç”¨ç›‘æ§

```go
func (t *Terminal) monitorMemoryUsage() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            
            log.Printf("å†…å­˜ç»Ÿè®¡:")
            log.Printf("  åˆ†é…å†…å­˜: %d KB", m.Alloc/1024)
            log.Printf("  æ€»åˆ†é…: %d KB", m.TotalAlloc/1024)
            log.Printf("  ç³»ç»Ÿå†…å­˜: %d KB", m.Sys/1024)
            log.Printf("  GC æ¬¡æ•°: %d", m.NumGC)
            
            // æ£€æŸ¥å†…å­˜æ³„æ¼
            if m.Alloc > 100*1024*1024 { // 100MB
                log.Printf("è­¦å‘Š: å†…å­˜ä½¿ç”¨è¿‡é«˜")
                runtime.GC() // å¼ºåˆ¶åƒåœ¾å›æ”¶
            }
            
        case <-t.ctx.Done():
            return
        }
    }
}
```

### åƒåœ¾å›æ”¶ä¼˜åŒ–

```go
func optimizeGC() {
    // è®¾ç½® GC ç›®æ ‡ç™¾åˆ†æ¯”
    debug.SetGCPercent(50) // é»˜è®¤æ˜¯ 100
    
    // è®¾ç½®æœ€å¤§å†…å­˜é™åˆ¶
    debug.SetMemoryLimit(200 * 1024 * 1024) // 200MB
    
    // å®šæœŸæ‰‹åŠ¨è§¦å‘ GC
    go func() {
        ticker := time.NewTicker(5 * time.Minute)
        defer ticker.Stop()
        
        for range ticker.C {
            runtime.GC()
        }
    }()
}
```

## âš¡ I/O æ€§èƒ½ä¼˜åŒ–

### ç¼“å†² I/O

```go
type BufferedPTY struct {
    pty        PTYInterface
    readBuf    *bufio.Reader
    writeBuf   *bufio.Writer
    bufSize    int
    flushTimer *time.Timer
    mu         sync.Mutex
}

func NewBufferedPTY(pty PTYInterface, bufSize int) *BufferedPTY {
    return &BufferedPTY{
        pty:     pty,
        readBuf: bufio.NewReaderSize(pty, bufSize),
        writeBuf: bufio.NewWriterSize(pty, bufSize),
        bufSize: bufSize,
    }
}

func (bp *BufferedPTY) Write(data []byte) (int, error) {
    bp.mu.Lock()
    defer bp.mu.Unlock()
    
    n, err := bp.writeBuf.Write(data)
    
    // è®¾ç½®å»¶è¿Ÿåˆ·æ–°
    if bp.flushTimer != nil {
        bp.flushTimer.Reset(10 * time.Millisecond)
    } else {
        bp.flushTimer = time.AfterFunc(10*time.Millisecond, func() {
            bp.mu.Lock()
            bp.writeBuf.Flush()
            bp.mu.Unlock()
        })
    }
    
    return n, err
}

func (bp *BufferedPTY) Read(data []byte) (int, error) {
    return bp.readBuf.Read(data)
}
```

### å¼‚æ­¥ I/O å¤„ç†

```go
type AsyncIOProcessor struct {
    inputChan  chan []byte
    outputChan chan []byte
    errorChan  chan error
    workers    int
    wg         sync.WaitGroup
}

func NewAsyncIOProcessor(workers int) *AsyncIOProcessor {
    return &AsyncIOProcessor{
        inputChan:  make(chan []byte, 100),
        outputChan: make(chan []byte, 100),
        errorChan:  make(chan error, 10),
        workers:    workers,
    }
}

func (aio *AsyncIOProcessor) Start() {
    for i := 0; i < aio.workers; i++ {
        aio.wg.Add(1)
        go aio.worker()
    }
}

func (aio *AsyncIOProcessor) worker() {
    defer aio.wg.Done()
    
    for data := range aio.inputChan {
        // å¤„ç†è¾“å…¥æ•°æ®
        processed := aio.processData(data)
        
        select {
        case aio.outputChan <- processed:
        case <-time.After(100 * time.Millisecond):
            // è¾“å‡ºé€šé“é˜»å¡ï¼Œè®°å½•é”™è¯¯
            aio.errorChan <- fmt.Errorf("output channel blocked")
        }
    }
}
```

## ğŸ”„ å¹¶å‘ä¼˜åŒ–

### Goroutine æ± 

```go
type GoroutinePool struct {
    taskChan chan func()
    wg       sync.WaitGroup
    size     int
    stop     chan struct{}
}

func NewGoroutinePool(size int) *GoroutinePool {
    pool := &GoroutinePool{
        taskChan: make(chan func(), size*2),
        size:     size,
        stop:     make(chan struct{}),
    }
    
    for i := 0; i < size; i++ {
        pool.wg.Add(1)
        go pool.worker()
    }
    
    return pool
}

func (p *GoroutinePool) worker() {
    defer p.wg.Done()
    
    for {
        select {
        case task := <-p.taskChan:
            task()
        case <-p.stop:
            return
        }
    }
}

func (p *GoroutinePool) Submit(task func()) error {
    select {
    case p.taskChan <- task:
        return nil
    case <-time.After(100 * time.Millisecond):
        return fmt.Errorf("goroutine pool is full")
    }
}
```

### æ— é”æ•°æ®ç»“æ„

```go
// æ— é”ç¯å½¢ç¼“å†²åŒº
type LockFreeRingBuffer struct {
    buffer []interface{}
    mask   uint64
    _      [8]uint64 // ç¼“å­˜è¡Œå¡«å……
    head   uint64
    _      [8]uint64 // ç¼“å­˜è¡Œå¡«å……
    tail   uint64
    _      [8]uint64 // ç¼“å­˜è¡Œå¡«å……
}

func NewLockFreeRingBuffer(size int) *LockFreeRingBuffer {
    // ç¡®ä¿å¤§å°æ˜¯ 2 çš„å¹‚
    if size&(size-1) != 0 {
        panic("size must be power of 2")
    }
    
    return &LockFreeRingBuffer{
        buffer: make([]interface{}, size),
        mask:   uint64(size - 1),
    }
}

func (rb *LockFreeRingBuffer) Push(item interface{}) bool {
    head := atomic.LoadUint64(&rb.head)
    tail := atomic.LoadUint64(&rb.tail)
    
    // æ£€æŸ¥ç¼“å†²åŒºæ˜¯å¦å·²æ»¡
    if head-tail >= uint64(len(rb.buffer)) {
        return false
    }
    
    rb.buffer[head&rb.mask] = item
    atomic.StoreUint64(&rb.head, head+1)
    return true
}

func (rb *LockFreeRingBuffer) Pop() (interface{}, bool) {
    head := atomic.LoadUint64(&rb.head)
    tail := atomic.LoadUint64(&rb.tail)
    
    // æ£€æŸ¥ç¼“å†²åŒºæ˜¯å¦ä¸ºç©º
    if head == tail {
        return nil, false
    }
    
    item := rb.buffer[tail&rb.mask]
    atomic.StoreUint64(&rb.tail, tail+1)
    return item, true
}
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡

### æ€§èƒ½æŒ‡æ ‡æ”¶é›†

```go
type PerformanceMetrics struct {
    StartTime     time.Time
    FrameCount    int64
    RenderTime    time.Duration
    InputLatency  time.Duration
    MemoryUsage   int64
    CPUUsage      float64
    mu            sync.RWMutex
}

func (pm *PerformanceMetrics) RecordFrame(renderTime time.Duration) {
    pm.mu.Lock()
    defer pm.mu.Unlock()
    
    pm.FrameCount++
    pm.RenderTime += renderTime
}

func (pm *PerformanceMetrics) GetFPS() float64 {
    pm.mu.RLock()
    defer pm.mu.RUnlock()
    
    elapsed := time.Since(pm.StartTime).Seconds()
    if elapsed == 0 {
        return 0
    }
    
    return float64(pm.FrameCount) / elapsed
}

func (pm *PerformanceMetrics) GetAverageRenderTime() time.Duration {
    pm.mu.RLock()
    defer pm.mu.RUnlock()
    
    if pm.FrameCount == 0 {
        return 0
    }
    
    return pm.RenderTime / time.Duration(pm.FrameCount)
}
```

### æ€§èƒ½æŠ¥å‘Š

```go
func (t *Terminal) generatePerformanceReport() {
    metrics := t.performanceMetrics
    
    report := fmt.Sprintf(`
æ€§èƒ½æŠ¥å‘Š
========
è¿è¡Œæ—¶é—´: %v
æ€»å¸§æ•°: %d
å¹³å‡FPS: %.2f
å¹³å‡æ¸²æŸ“æ—¶é—´: %v
è¾“å…¥å»¶è¿Ÿ: %v
å†…å­˜ä½¿ç”¨: %d KB
CPUä½¿ç”¨: %.2f%%
`,
        time.Since(metrics.StartTime),
        metrics.FrameCount,
        metrics.GetFPS(),
        metrics.GetAverageRenderTime(),
        metrics.InputLatency,
        metrics.MemoryUsage/1024,
        metrics.CPUUsage,
    )
    
    log.Println(report)
}
```

## ğŸ§ª æ€§èƒ½æµ‹è¯•

### åŸºå‡†æµ‹è¯•

```go
func BenchmarkTerminalRender(b *testing.B) {
    term := setupBenchmarkTerminal(b)
    defer term.Stop()
    
    // å¡«å……ç»ˆç«¯å†…å®¹
    fillTerminalWithTestData(term, 1000)
    
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        term.Render()
    }
}

func BenchmarkInputProcessing(b *testing.B) {
    term := setupBenchmarkTerminal(b)
    defer term.Stop()
    
    testInput := []byte("echo hello world\n")
    
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        term.ProcessInput(testInput)
    }
}

func BenchmarkColorParsing(b *testing.B) {
    colorCodes := []string{
        "\033[31m",
        "\033[42m", 
        "\033[1;33m",
        "\033[38;5;196m",
        "\033[38;2;255;128;0m",
    }
    
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        for _, code := range colorCodes {
            parseColorCode(code)
        }
    }
}
```

### å‹åŠ›æµ‹è¯•

```go
func TestTerminalStressTest(t *testing.T) {
    if testing.Short() {
        t.Skip("è·³è¿‡å‹åŠ›æµ‹è¯•")
    }
    
    term := setupTestTerminal(t)
    defer term.Stop()
    
    // å¹¶å‘å†™å…¥æµ‹è¯•
    const numWorkers = 10
    const messagesPerWorker = 1000
    
    var wg sync.WaitGroup
    errors := make(chan error, numWorkers)
    
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            
            for j := 0; j < messagesPerWorker; j++ {
                message := fmt.Sprintf("Worker %d Message %d\n", workerID, j)
                if _, err := term.Write([]byte(message)); err != nil {
                    errors <- err
                    return
                }
            }
        }(i)
    }
    
    wg.Wait()
    close(errors)
    
    // æ£€æŸ¥é”™è¯¯
    for err := range errors {
        t.Errorf("å‹åŠ›æµ‹è¯•å¤±è´¥: %v", err)
    }
    
    // éªŒè¯æ€§èƒ½æŒ‡æ ‡
    metrics := term.GetPerformanceMetrics()
    assert.Less(t, metrics.GetAverageRenderTime(), 16*time.Millisecond) // < 16ms (60 FPS)
    assert.Greater(t, metrics.GetFPS(), 30.0) // > 30 FPS
}
```

## ğŸ”§ é…ç½®ä¼˜åŒ–

### æ€§èƒ½é…ç½®é€‰é¡¹

```go
type PerformanceConfig struct {
    // æ¸²æŸ“ä¼˜åŒ–
    EnableVSync        bool          `json:"enable_vsync"`
    TargetFPS          int           `json:"target_fps"`
    EnableDirtyRender  bool          `json:"enable_dirty_render"`
    
    // å†…å­˜ä¼˜åŒ–
    BufferSize         int           `json:"buffer_size"`
    MaxCacheSize       int           `json:"max_cache_size"`
    GCPercent          int           `json:"gc_percent"`
    
    // å¹¶å‘ä¼˜åŒ–
    WorkerCount        int           `json:"worker_count"`
    EnableGoroutinePool bool         `json:"enable_goroutine_pool"`
    
    // I/O ä¼˜åŒ–
    ReadBufferSize     int           `json:"read_buffer_size"`
    WriteBufferSize    int           `json:"write_buffer_size"`
    FlushInterval      time.Duration `json:"flush_interval"`
}

func DefaultPerformanceConfig() PerformanceConfig {
    return PerformanceConfig{
        EnableVSync:         true,
        TargetFPS:          60,
        EnableDirtyRender:  true,
        BufferSize:         32768,
        MaxCacheSize:       1000,
        GCPercent:          50,
        WorkerCount:        runtime.NumCPU(),
        EnableGoroutinePool: true,
        ReadBufferSize:     8192,
        WriteBufferSize:    8192,
        FlushInterval:      10 * time.Millisecond,
    }
}
```

---

æ›´å¤šä¿¡æ¯è¯·å‚è€ƒï¼š
- [æ¶æ„è®¾è®¡](./architecture.md)
- [æµ‹è¯•æŒ‡å—](./testing-guide.md)
- [æ•…éšœæ’é™¤](./troubleshooting.md)
